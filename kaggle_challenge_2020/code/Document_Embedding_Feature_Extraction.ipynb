{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Altegrad_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4r7OuyITbBj",
        "colab_type": "text"
      },
      "source": [
        "#Loading Packages and Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-BDojHCUuWJ",
        "colab_type": "code",
        "outputId": "6be92b0f-f6db-4e24-e2d9-8206c28af278",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "# Permission to use the drive to extract data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VFTbzb_8uwn",
        "colab_type": "code",
        "outputId": "86ca54af-feb3-46b3-eba8-2d5bb36d8fd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip3 install tqdm --upgrade"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tqdm in /usr/local/lib/python3.6/dist-packages (4.43.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ3VxXfwxuiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "from tqdm.notebook import tqdm \n",
        "import pandas as pd \n",
        "from sklearn.preprocessing import OrdinalEncoder "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnjlN7GKUzNH",
        "colab_type": "code",
        "outputId": "ca377441-1658-4993-c147-5966b45d2fa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd '/content/gdrive/My Drive/Altegrad'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Altegrad\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzsaWfbBTfbu",
        "colab_type": "text"
      },
      "source": [
        "### Load Train Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akAFVIylEyfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv('./embeds/' + 'train_noduplicates.csv', header = None)\n",
        "train_data.columns = ['File', 'Type']\n",
        "\n",
        "test_data = pd.read_csv('./embeds/' + 'test.csv', header = None)\n",
        "test_data.columns = ['File']\n",
        "\n",
        "enc = OrdinalEncoder()\n",
        "X = train_data['Type']\n",
        "labels = enc.fit_transform(np.array(X).reshape(-1,1))\n",
        "train_data['Labels'] = labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xTb-9QyTiDp",
        "colab_type": "text"
      },
      "source": [
        "### Load Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjzqmDXBW5Oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_data = './text/'\n",
        "\n",
        "import pickle\n",
        "Load_embegginds = False\n",
        "\n",
        "if Load_embegginds == True:\n",
        "  my_vectors = {}\n",
        "  i = 0\n",
        "  for line in open('./cc.fr.300.vec'):\n",
        "      fields = line.strip().split(\" \") \n",
        "      nom = fields[0].lower()\n",
        "      if nom.isalpha():\n",
        "          my_vectors[nom] = [float(v) for v in fields[1:]]\n",
        "\n",
        "else:\n",
        "  with open('./embeds/pickle_embed.pickle', 'rb') as handle:\n",
        "    embeddings = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SnmZc6OTj96",
        "colab_type": "text"
      },
      "source": [
        "### Load Vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvGRLgEXW5kE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('./embeds/vocab_clean.pickle', 'rb') as handle:\n",
        "  vocab = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU_6uoNrW55s",
        "colab_type": "code",
        "outputId": "e040d1f7-05a9-4ef4-eb2c-cd15bcdaf292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(vocab), len(embeddings)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6960, 1142478)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHWxOkP9astX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_file_embedding(file):\n",
        "  file = './embeds/Vocab_occurences/pickles/' + file\n",
        "  with open(file + '.pickle', 'rb') as handle:\n",
        "    my_data = pickle.load(handle)\n",
        "\n",
        "  w_c = max(vocab.values()) / max(my_data.values())\n",
        "  common_vocab = {k: float(w_c * my_data[k]/vocab[k]) for k in my_data.keys() & vocab}\n",
        "\n",
        "  embedding_words = {k: np.array(embeddings[k]) * common_vocab[k] for k in common_vocab.keys() & embeddings}\n",
        "\n",
        "  vect_file = sum(embedding_words.values())\n",
        "\n",
        "  return vect_file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3boOo9Otx_zX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = extract_file_embedding('0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8gZzg8JgAIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_embedding_doc = False\n",
        "\n",
        "if train_embedding_doc == True:\n",
        "\n",
        "  from os import listdir\n",
        "  test = []\n",
        "  vocab_embedding_docs = {}\n",
        "  i = 0\n",
        "\n",
        "  for file in tqdm(listdir('./embeds/Vocab_occurences/pickles')):\n",
        "    file = file.split('.')[0]\n",
        "    try:\n",
        "      if (len(extract_file_embedding(file))) == 300:\n",
        "        vocab_embedding_docs[file] = extract_file_embedding(file)\n",
        "    except:\n",
        "      vocab_embedding_docs[file] = np.array([0 for t in range(300)])\n",
        "      test.append(file)\n",
        "      pass\n",
        "\n",
        "else:\n",
        "  with open('./embeds/doc_vocab_embed.pickle', 'rb') as handle:\n",
        "    vocab_embedding_docs = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3vVxI7G3_px",
        "colab_type": "code",
        "outputId": "35a5cff6-eedc-42d5-bc23-8122b31454fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(vocab_embedding_docs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2555"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHUdHpFYy_zM",
        "colab_type": "code",
        "outputId": "187dc4a0-e652-45ff-f9fe-77d8d09f7db2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "my_list = []\n",
        "X = []\n",
        "y = []\n",
        "for element in vocab_embedding_docs.keys():\n",
        "  try:\n",
        "    if len(vocab_embedding_docs[element]) == 300:\n",
        "      y_t = train_data[train_data['File'] == int(element)]['Labels'].iloc[0]\n",
        "      y.append(y_t)\n",
        "      X.append(vocab_embedding_docs[element])\n",
        "  except:\n",
        "    my_list.append(element)\n",
        "\n",
        "X = np.vstack(X)\n",
        "\n",
        "y = np.array(y).reshape(-1, 1)\n",
        "X.shape, y.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1994, 300), (1994, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBohA--t-fhD",
        "colab_type": "text"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GGEQuxOTtNE",
        "colab_type": "text"
      },
      "source": [
        "### Using MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wcolk7Qi2Hoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "from keras.constraints import unit_norm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVlsOXEr3Mz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "num_classes = 8\n",
        "epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxcW0Y8bzD90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(300,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='tanh'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='tanh', kernel_constraint=unit_norm()))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu', bias = True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCVU97f0Ccd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_export = []\n",
        "my_list = []\n",
        "for element in test_data['File']:\n",
        "  try:\n",
        "    if len(vocab_embedding_docs[str(element)]) == 300:\n",
        "      X_export.append(vocab_embedding_docs[str(element)])\n",
        "  except:\n",
        "    my_list.append(element)\n",
        "\n",
        "X_export = np.vstack(X_export)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhsvYOybH0gh",
        "colab_type": "text"
      },
      "source": [
        "## Using LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JBmgSCB-lOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logging.getLogger(\"pytorch_transformers.tokenization_utils\").setLevel(logging.ERROR)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfMdoE53-rIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loglikelihood_score(y_true, predictions, classes_order):\n",
        "    dic = {v:k for k, v in enumerate(classes_order)}\n",
        "    loss = 0\n",
        "    for i, cls in enumerate(y_true) :\n",
        "        loss -= np.log(predictions[i, dic[cls]])\n",
        "    loss = loss/len(y_true)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP7bsUmqCkS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9IRINFsTzT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid={\"C\":np.logspace(-1,3, num = 30)}\n",
        "\n",
        "logreg = LogisticRegression(solver='lbfgs',  multi_class='auto', max_iter=25000, n_jobs=-1)\n",
        "\n",
        "classes_order = LogisticRegression(solver='lbfgs',  multi_class='auto').fit(x_train[:, :2], y_train).classes_\n",
        "score_function = make_scorer(loglikelihood_score, greater_is_better=False, classes_order=classes_order, needs_proba=True)\n",
        "\n",
        "logreg_cv = GridSearchCV(logreg,grid,cv=3, verbose=3, n_jobs=-1, scoring=score_function)\n",
        "\n",
        "logreg_cv.fit(x_train, y_train)\n",
        "\n",
        "print(logreg_cv.best_params_)\n",
        "print('Score on the local test : ', logreg_cv.best_score_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45LWdI7XCrUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}